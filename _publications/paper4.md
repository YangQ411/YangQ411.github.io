---
title: "Comparative Study of LoRA placement Strategies for Parameter-Efficient Fine-Tuning of LLMs"
collection: publications
category: conferences
permalink: /publication/paper4
excerpt: 'ÔÅ¨Conducted a comparative study of Low-Rank Adaptation (LoRA) placement strategies on multiple open-source LLMs (Llama3.2-1B, Gemma3-1B, Qwen3-0.6B, Falcon-1B) Evaluated LoRA placements in different LLM blocks (attention, MLP, output head, embedding, and combinations) with respect to model performance, efficiency, and trade-offs Benchmarked models on MMLU, analyzing accuracy, throughput, memory, and parameter efficiency; designed a new metric (Im/P, Improvement per % Parameters) and applied Pareto analysis to identify optimal configurations Provided evidence-based recommendations for LoRA placement strategies, focusing on non-trivial architecture-specific behaviors and offering practical guidance for future research and Industrial deployment'
date: 2025-02-17
venue: 'GitHub Journal of Bugs'
paperurl: ''
---

**Abstract:** The contents above will be part of a list of publications, if the user clicks the link for the publication than the contents of section will be rendered as a full page, allowing you to provide more information about the paper for the reader. When publications are displayed as a single page, the contents of the above "citation" field will automatically be included below this section in a smaller font.
